# RAG å…¨æµç¨‹è§£æ

## ğŸ“‹ æ¦‚è¿°

RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§å°†ä¿¡æ¯æ£€ç´¢ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»“åˆçš„æŠ€æœ¯æ¶æ„ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å¯é çš„å›ç­”ã€‚

## ğŸ”„ RAG æ ¸å¿ƒæµç¨‹

### 1. æ•°æ®åŠ è½½ï¼ˆDocument Loadingï¼‰

**ç›®çš„**ï¼šå°†å„ç§æ ¼å¼çš„æ–‡æ¡£åŠ è½½åˆ°ç»Ÿä¸€çš„æ•°æ®ç»“æ„ä¸­ã€‚

**æ”¯æŒçš„æ•°æ®æº**ï¼š
- **éç»“æ„åŒ–æ–‡æ¡£**ï¼šPDFã€Wordã€TXTã€MD
- **åŠç»“æ„åŒ–æ•°æ®**ï¼šWeb é¡µé¢ã€Markdown æ–‡ä»¶
- **ç»“æ„åŒ–æ•°æ®**ï¼šæ•°æ®åº“è®°å½•ã€CSV æ–‡ä»¶ã€JSON æ•°æ®

**ä½¿ç”¨çš„å·¥å…·**ï¼ˆLangChainï¼‰ï¼š
```python
# PDF æ–‡æ¡£åŠ è½½
from langchain_community.document_loaders import PyPDFLoader

loader = PyPDFLoader("docs/æ•™å­¦æ–‡ä»¶/ragfiles/2025å¹´æœ¬ç§‘æ–°ç”ŸæŠ¥åˆ°æ‰‹å†Œ.pdf")
documents = loader.load()

# Word æ–‡æ¡£åŠ è½½
from langchain_community.document_loaders import Docx2txtLoader

loader = Docx2txtLoader("docs/æ•™å­¦æ–‡ä»¶/ragfiles/é™¢æ ¡ç®€ä»‹.docx")
documents = loader.load()

# æ–‡æœ¬æ–‡ä»¶åŠ è½½
from langchain_community.document_loaders import TextLoader

loader = TextLoader("docs/æ•™å­¦æ–‡ä»¶/ragfiles/README.md", encoding='utf-8')
documents = loader.load()
```

**æ³¨æ„äº‹é¡¹**ï¼š
- ä¸åŒåŠ è½½å™¨è¿”å›çš„æ–‡æ¡£å¯¹è±¡ç»“æ„å¯èƒ½ä¸åŒ
- å¤§æ–‡ä»¶éœ€è¦åˆ†æ‰¹åŠ è½½ï¼Œé¿å…å†…å­˜æº¢å‡º
- éœ€è¦å¤„ç†åŠ è½½å¤±è´¥çš„æƒ…å†µï¼ˆå¦‚æ–‡ä»¶æŸåï¼‰

### 2. æ–‡æ¡£åˆ‡åˆ†ï¼ˆDocument Splittingï¼‰

**ç›®çš„**ï¼šå°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºè¯­ä¹‰å®Œæ•´çš„å°å—ï¼Œä¾¿äºå‘é‡åŒ–å’Œæ£€ç´¢ã€‚

**åˆ‡åˆ†åŸåˆ™**ï¼š
1. **è¯­ä¹‰å®Œæ•´æ€§**ï¼šåˆ‡åˆ†è¾¹ç•Œåº”ä¼˜å…ˆåœ¨æ®µè½ã€å¥å­ç­‰è¯­ä¹‰è¾¹ç•Œ
2. **åˆç†çš„é‡å **ï¼šç›¸é‚»æ–‡æœ¬å—åº”æœ‰ä¸€å®šé‡å ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±
3. **åˆé€‚çš„å—å¤§å°**ï¼šé€šå¸¸ 400-800 å­—ç¬¦ï¼Œå–å†³äº Embedding æ¨¡å‹å’Œ LLM ä¸Šä¸‹æ–‡çª—å£

**ä½¿ç”¨çš„å·¥å…·**ï¼ˆLangChainï¼‰ï¼š
```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

# åˆ›å»ºæ–‡æœ¬åˆ‡åˆ†å™¨
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,        # æ–‡æœ¬å—å¤§å°
    chunk_overlap=50,        # æ–‡æœ¬å—é‡å 
    length_function=len,      # é•¿åº¦è®¡ç®—å‡½æ•°
    separators=[           # è¯­ä¹‰æ„ŸçŸ¥çš„åˆ†éš”ç¬¦ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        "\n\n",  # æ®µè½åˆ†éš”
        "\n",     # è¡Œåˆ†éš”
        "ã€‚",    # ä¸­æ–‡å¥å·
        "ï¼",     # ä¸­æ–‡æ„Ÿå¹å·
        "ï¼Ÿ",     # ä¸­æ–‡é—®å·
        ".",     # è‹±æ–‡å¥å·
        "!",     # è‹±æ–‡æ„Ÿå¹å·
        "?",     # è‹±æ–‡é—®å·
        " ",     # ç©ºæ ¼
        ""       # ç©ºå­—ç¬¦ä¸²ï¼ˆå…œåº•ï¼‰
    ]
)

# æ‰§è¡Œæ–‡æ¡£åˆ‡åˆ†
splits = text_splitter.split_documents(documents)

print(f"åˆ‡åˆ†åæ–‡æœ¬å—æ•°é‡ï¼š{len(splits)}")
```

**åˆ‡åˆ†å‚æ•°è¯´æ˜**ï¼š
- `chunk_size`ï¼šæ¯ä¸ªæ–‡æœ¬å—çš„æœ€å¤§å­—ç¬¦æ•°
  - å¤ªå°ï¼šæ£€ç´¢ç»“æœå¯èƒ½ä¿¡æ¯ä¸è¶³
  - å¤ªå¤§ï¼šå¯èƒ½å¯¼è‡´ LLM ä¸Šä¸‹æ–‡æº¢å‡ºï¼Œé™ä½æ£€ç´¢å‡†ç¡®æ€§
  - æ¨èå€¼ï¼š400-800ï¼ˆæ ¹æ® Embedding æ¨¡å‹å’Œ LLM è°ƒæ•´ï¼‰

- `chunk_overlap`ï¼šç›¸é‚»æ–‡æœ¬å—çš„é‡å å­—ç¬¦æ•°
  - å¤ªå°ï¼šå¯èƒ½åœ¨è¯­ä¹‰è¾¹ç•Œåˆ‡åˆ†ï¼Œå¯¼è‡´ä¿¡æ¯æ–­è£‚
  - å¤ªå¤§ï¼šå¢åŠ å­˜å‚¨å’Œè®¡ç®—æˆæœ¬
  - æ¨èå€¼ï¼šchunk_size çš„ 10-15%

- `separators`ï¼šåˆ†éš”ç¬¦åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½æ’åºï¼‰
  - ä¼˜å…ˆä½¿ç”¨è¯­ä¹‰æ„ŸçŸ¥çš„åˆ†éš”ç¬¦ï¼ˆæ®µè½ã€å¥å­ï¼‰
  - ç„¶åä½¿ç”¨é€šç”¨åˆ†éš”ç¬¦ï¼ˆç©ºæ ¼ï¼‰
  - æœ€åä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºå…œåº•

**åˆ‡åˆ†åçš„æ•°æ®ç»“æ„**ï¼š
```python
[
    Document(
        page_content="æ–°ç”ŸæŠ¥åˆ°æ—¶é—´ï¼šæ¯å¹´ 9 æœˆ 1 æ—¥è‡³ 9 æœˆ 5 æ—¥ã€‚æŠ¥åˆ°åœ°ç‚¹ï¼šå­¦æ ¡ä¸»æ¥¼å¤§å…ã€‚",
        metadata={
            'source': 'docs/æ•™å­¦æ–‡ä»¶/ragfiles/2025å¹´æœ¬ç§‘æ–°ç”ŸæŠ¥åˆ°æ‰‹å†Œ.pdf',
            'page': 1,
            'chunk_id': 0
        }
    ),
    # ... æ›´å¤šæ–‡æœ¬å—
]
```

**å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ**ï¼š

**é—®é¢˜ 1ï¼šæ–‡æœ¬å—è¯­ä¹‰ä¸å®Œæ•´**
- **åŸå› **ï¼šåˆ†éš”ç¬¦è®¾ç½®ä¸åˆç†ï¼Œåœ¨å¥å­ä¸­é—´åˆ‡åˆ†
- **è§£å†³**ï¼šè°ƒæ•´ separators åˆ—è¡¨ï¼Œç¡®ä¿åŒ…å«ä¸­æ–‡æ ‡ç‚¹ç¬¦å·

**é—®é¢˜ 2ï¼šæ£€ç´¢ç»“æœé‡å¤**
- **åŸå› **ï¼šchunk_overlap è®¾ç½®è¿‡å¤§
- **è§£å†³**ï¼šå‡å°‘é‡å æ¯”ä¾‹ï¼Œæˆ–åœ¨æ£€ç´¢åå»é‡

**é—®é¢˜ 3ï¼šç‰¹å®šé¢†åŸŸä¸“ä¸šæœ¯è¯­è¢«é”™è¯¯åˆ‡åˆ†**
- **åŸå› **ï¼šé€šç”¨åˆ†éš”ç¬¦ä¸é€‚åˆä¸“ä¸šé¢†åŸŸ
- **è§£å†³**ï¼šä½¿ç”¨è‡ªå®šä¹‰åˆ†éš”ç¬¦ï¼Œæˆ–ä½¿ç”¨è¯­ä¹‰æ„ŸçŸ¥çš„åˆ‡åˆ†æ–¹æ³•

### 3. å‘é‡åŒ–ï¼ˆEmbeddingsï¼‰

**ç›®çš„**ï¼šå°†æ–‡æœ¬å—è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºï¼Œä½¿å…¶èƒ½åœ¨å‘é‡ç©ºé—´ä¸­è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ã€‚

**å‘é‡è¡¨ç¤ºåŸç†**ï¼š
- æ–‡æœ¬é€šè¿‡ Embedding æ¨¡å‹è½¬æ¢ä¸ºé«˜ç»´å‘é‡
- ç›¸ä¼¼çš„æ–‡æœ¬åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»è¾ƒè¿‘
- å¯ä»¥ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ã€æ¬§æ°è·ç¦»ç­‰åº¦é‡ç›¸ä¼¼æ€§

**å¸¸ç”¨çš„ Embedding æ¨¡å‹**ï¼š
- **è½»é‡çº§**ï¼š
  - `BAAI/bge-small` - é€Ÿåº¦å¿«ï¼Œé€‚åˆå¿«é€ŸåŸå‹
  - `BAAI/bge-base` - å¹³è¡¡æ€§èƒ½å’Œè´¨é‡
  - `BAAI/bge-large` - æ›´é«˜è´¨é‡ï¼Œä½†æ›´æ…¢

- **ä¸­é‡çº§**ï¼š
  - `BAAI/bge-m3` - å¤šè¯­è¨€æ”¯æŒï¼Œè´¨é‡é«˜
  - `intfloat/e5-mistral-7b-instruct` - ä¸­è‹±åŒè¯­ï¼Œè´¨é‡ä¼˜ç§€

- **é‡é‡çº§**ï¼š
  - `text-embedding-3-large` - OpenAI å•†ä¸šæ¨¡å‹
  - `mxbai-embed-large` - è‹±æ–‡è´¨é‡æœ€ä½³

**ä½¿ç”¨çš„å·¥å…·**ï¼ˆLangChainï¼‰ï¼š
```python
from langchain_community.embeddings import SentenceTransformerEmbeddings
from sentence_transformers import SentenceTransformer

# åˆå§‹åŒ– Embedding æ¨¡å‹
embedding = SentenceTransformerEmbeddings(
    model_name="BAAI/bge-m3",  # å¤šè¯­è¨€æ”¯æŒï¼Œè´¨é‡é«˜
    model_kwargs={'device': 'cpu'},  # ä½¿ç”¨ CPU
    encode_kwargs={'normalize_embeddings': True}  # å½’ä¸€åŒ–å‘é‡
)

# ç”Ÿæˆæ–‡æ¡£å‘é‡
vectors = embedding.embed_documents(
    texts=[split.page_content for split in splits],
    batch_size=32  # æ‰¹æ¬¡å¤„ç†
    show_progress=True  # æ˜¾ç¤ºè¿›åº¦
)

print(f"ç”Ÿæˆäº† {len(vectors)} ä¸ªå‘é‡ï¼Œæ¯ä¸ªå‘é‡ç»´åº¦ï¼š{len(vectors[0])}")
```

**Embedding æ¨¡å‹é€‰æ‹©å»ºè®®**ï¼š

**åœºæ™¯ 1ï¼šå¿«é€ŸåŸå‹å¼€å‘**
- æ¨èï¼š`BAAI/bge-small` æˆ– `intfloat/e5-small-v2`
- åŸå› ï¼šé€Ÿåº¦å¿«ï¼Œèµ„æºæ¶ˆè€—å°‘

**åœºæ™¯ 2ï¼šä¸­æ–‡ä¸ºä¸»çš„ä¸­æ–‡åº”ç”¨**
- æ¨èï¼š`BAAI/bge-m3` æˆ– `mxbai-embed-large`
- åŸå› ï¼šå¯¹ä¸­æ–‡ç†è§£èƒ½åŠ›å¼º

**åœºæ™¯ 3ï¼šä¸­è‹±åŒè¯­åº”ç”¨**
- æ¨èï¼š`intfloat/e5-mistral-7b-instruct`
- åŸå› ï¼šåŒè¯­è´¨é‡éƒ½å¾ˆå¥½

**åœºæ™¯ 4ï¼šå•†ä¸šåº”ç”¨ï¼Œè¿½æ±‚æœ€ä½³è´¨é‡**
- æ¨èï¼š`text-embedding-3-large` æˆ– `mxbai-embed-large`
- åŸå› ï¼šè´¨é‡æœ€ä½³ï¼Œä½†éœ€è¦ OpenAI API å¯†é’¥

**å‘é‡ç»´åº¦è¯´æ˜**ï¼š
- å°æ¨¡å‹ï¼š384-768 ç»´
- ä¸­æ¨¡å‹ï¼š768-1024 ç»´
- å¤§æ¨¡å‹ï¼š1024-3072 ç»´
- å‘é‡ç»´åº¦è¶Šé«˜ï¼Œç†è®ºä¸Šè¯­ä¹‰è¡¨ç¤ºèƒ½åŠ›è¶Šå¼ºï¼Œä½†è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ä¹Ÿè¶Šé«˜

### 4. å­˜å‚¨ï¼ˆVector Storeï¼‰

**ç›®çš„**ï¼šæŒä¹…åŒ–å­˜å‚¨æ–‡æ¡£å‘é‡å’Œå…ƒæ•°æ®ï¼Œæ”¯æŒé«˜æ•ˆçš„ç›¸ä¼¼åº¦æŸ¥è¯¢ã€‚

**å¸¸ç”¨çš„å‘é‡æ•°æ®åº“**ï¼š
- **ChromaDB**ï¼šè½»é‡çº§ï¼Œå¼€æºï¼Œé€‚åˆæœ¬åœ°å¼€å‘å’Œæµ‹è¯•
- **Qdrant**ï¼šæ€§èƒ½ä¼˜ç§€ï¼Œæ”¯æŒå¤šç§ APIï¼Œæ”¯æŒ GPU åŠ é€Ÿ
- **Pinecone**ï¼šäº‘æœåŠ¡ï¼Œæ— éœ€è¿ç»´ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ
- **Weaviate**ï¼šäº‘æœåŠ¡ï¼Œå¯è§†åŒ–ç•Œé¢ä¼˜ç§€ï¼Œé€‚åˆå¿«é€ŸåŸå‹

**ä½¿ç”¨çš„å·¥å…·**ï¼ˆLangChainï¼‰ï¼š
```python
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

# åˆå§‹åŒ– Embedding æ¨¡å‹
embedding = SentenceTransformerEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

# åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆæœ¬åœ°å­˜å‚¨ï¼‰
vector_store = Chroma.from_documents(
    documents=splits,
    embedding=embedding,
    persist_directory="./db/chroma_db",  # æŒä¹…åŒ–ç›®å½•
    collection_name="campus_knowledge"  # é›†åˆåç§°
)

# æŒä¹…åŒ–åˆ°ç£ç›˜
vector_store.persist()

print("å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸï¼")
```

**å‘é‡æ•°æ®åº“é€‰æ‹©å»ºè®®**ï¼š

**åœºæ™¯ 1ï¼šæœ¬åœ°å¼€å‘å’Œæµ‹è¯•**
- æ¨èï¼šChromaDB
- åŸå› ï¼šç®€å•æ˜“ç”¨ï¼Œæ— éœ€é¢å¤–ä¾èµ–ï¼Œæœ¬åœ°å­˜å‚¨

**åœºæ™¯ 2ï¼šç”Ÿäº§ç¯å¢ƒï¼Œè¿½æ±‚æ€§èƒ½**
- æ¨èï¼šQdrant æˆ– Pinecone
- åŸå› ï¼šæ€§èƒ½ä¼˜ç§€ï¼Œæ”¯æŒé«˜å¹¶å‘ï¼Œæä¾›äº‘æœåŠ¡

**åœºæ™¯ 3ï¼šå¿«é€ŸåŸå‹å’Œå¯è§†åŒ–**
- æ¨èï¼šWeaviate
- åŸå› ï¼šæä¾›å¯è§†åŒ–ç•Œé¢ï¼Œä¾¿äºè°ƒè¯•å’Œæ¢ç´¢

**å­˜å‚¨ä¼˜åŒ–å»ºè®®**ï¼š
1. **æ·»åŠ ç´¢å¼•**ï¼šæ ¹æ®æŸ¥è¯¢æ¨¡å¼æ·»åŠ åˆé€‚çš„ç´¢å¼•ï¼ˆå¦‚ HNSWï¼‰
2. **æ‰¹é‡æ“ä½œ**ï¼šä½¿ç”¨æ‰¹é‡æ’å…¥/æŸ¥è¯¢ï¼Œå‡å°‘ç½‘ç»œå¾€è¿”
3. **å®šæœŸæ¸…ç†**ï¼šåˆ é™¤è¿‡æ—¶æˆ–ä¸å†éœ€è¦çš„å‘é‡æ•°æ®
4. **ç›‘æ§æ€§èƒ½**ï¼šç›‘æ§æŸ¥è¯¢å»¶è¿Ÿå’Œååé‡ï¼ŒåŠæ—¶ä¼˜åŒ–

### 5. æ£€ç´¢ï¼ˆRetrievalï¼‰

**ç›®çš„**ï¼šæ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£å—ã€‚

**æ£€ç´¢æ–¹æ³•**ï¼š

#### 5.1 ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆSimilarity Searchï¼‰

åŸºäºå‘é‡ç›¸ä¼¼åº¦è¿›è¡Œæ£€ç´¢ï¼Œè¿”å›æœ€ç›¸ä¼¼çš„ k ä¸ªæ–‡æ¡£å—ã€‚

```python
def similarity_search(query: str, k: int = 3):
    """ç›¸ä¼¼åº¦æ£€ç´¢"""
    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = embedding.embed_query(query)

    # æ‰§è¡Œç›¸ä¼¼åº¦æ£€ç´¢
    results = vector_store.similarity_search_by_vector(
        embedding=query_embedding,
        k=k
    )

    return results
```

**ç‰¹ç‚¹**ï¼š
- ç®€å•ç›´è§‚ï¼ŒåŸºäºå‘é‡ç›¸ä¼¼åº¦
- æŸ¥è¯¢é€Ÿåº¦å¿«
- å¯èƒ½è¿”å›è¯­ä¹‰ç›¸å…³ä½†å†…å®¹é‡å¤çš„ç»“æœ

#### 5.2 æœ€å¤§è¾¹é™…ç›¸å…³æ€§æ£€ç´¢ï¼ˆMMR Searchï¼‰

åœ¨ç›¸å…³æ€§å’Œå¤šæ ·æ€§ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œé¿å…è¿”å›è¿‡äºç›¸ä¼¼çš„æ–‡æ¡£å—ã€‚

```python
def mmr_search(query: str, k: int = 3, fetch_k: int = 10):
    """æœ€å¤§è¾¹é™…ç›¸å…³æ€§æ£€ç´¢"""
    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = embedding.embed_query(query)

    # æ‰§è¡Œ MMR æ£€ç´¢
    results = vector_store.max_marginal_relevance_search(
        query_embedding=query_embedding,
        k=k,
        fetch_k=fetch_k  # ä» fetch_k ä¸ªå€™é€‰ä¸­é€‰æ‹© k ä¸ª
    )

    return results
```

**ç‰¹ç‚¹**ï¼š
- å¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
- æ£€ç´¢ç»“æœæ›´ä¸°å¯Œ
- æŸ¥è¯¢é€Ÿåº¦ç¨æ…¢ï¼ˆéœ€è¦ä»æ›´å¤šå€™é€‰ä¸­é€‰æ‹©ï¼‰

#### 5.3 æ··åˆæ£€ç´¢ï¼ˆHybrid Searchï¼‰

ç»“åˆå…³é”®è¯æ£€ç´¢ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰å’Œè¯­ä¹‰æ£€ç´¢ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰ã€‚

```python
from langchain.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever

# å…³é”®è¯æ£€ç´¢å™¨
keyword_retriever = BM25Retriever.from_documents(
    documents=splits,
    k=5
)

# è¯­ä¹‰æ£€ç´¢å™¨
semantic_retriever = vector_store.as_retriever(
    search_kwargs={"k": 3}
)

# æ··åˆæ£€ç´¢å™¨ï¼ˆåŠ æƒèåˆï¼‰
hybrid_retriever = EnsembleRetriever(
    retrievers=[keyword_retriever, semantic_retriever],
    weights=[0.3, 0.7],  # å…³é”®è¯ 30%ï¼Œè¯­ä¹‰ 70%
    search_type="similarity"
)

# æ‰§è¡Œæ··åˆæ£€ç´¢
results = hybrid_retriever.invoke(query)
```

**ç‰¹ç‚¹**ï¼š
- ç»“åˆç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…çš„ä¼˜ç‚¹
- æé«˜å¬å›ç‡ï¼ˆRelevanceï¼‰
- æŸ¥è¯¢é€Ÿåº¦å–å†³äºä½¿ç”¨çš„æ–¹æ³•

**æ£€ç´¢æ–¹æ³•å¯¹æ¯”**ï¼š

| æ–¹æ³• | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| ç›¸ä¼¼åº¦æ£€ç´¢ | ç®€å•ã€å¿«é€Ÿ | å¯èƒ½é‡å¤ã€å¤šæ ·æ€§å·® | å¿«é€ŸåŸå‹ã€ç®€å•æŸ¥è¯¢ |
| MMR æ£€ç´¢ | å¤šæ ·æ€§å¥½ã€å¹³è¡¡ç›¸å…³ | ç¨æ…¢ã€å‚æ•°æ•æ„Ÿ | éœ€è¦å¤šæ ·æ€§çš„åœºæ™¯ |
| æ··åˆæ£€ç´¢ | å¬å›ç‡é«˜ã€å‡†ç¡®åº¦é«˜ | å¤æ‚åº¦é«˜ã€è®¡ç®—æˆæœ¬é«˜ | ç”Ÿäº§ç¯å¢ƒã€å¤æ‚æŸ¥è¯¢ |

### 6. ç”Ÿæˆï¼ˆGenerationï¼‰

**ç›®çš„**ï¼šåˆ©ç”¨ LLM ç”Ÿæˆæœ€ç»ˆçš„å›ç­”ï¼ŒåŸºäºæ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å—ã€‚

**ä½¿ç”¨çš„å·¥å…·**ï¼ˆLangChainï¼‰ï¼š
```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# åˆ›å»º LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# åˆ›å»º RAG é“¾
rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",  # ç®€å•åœ°å°†æ‰€æœ‰æ£€ç´¢ç»“æœæ‹¼æ¥
    retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True
)

# æ‰§è¡ŒæŸ¥è¯¢
query = "æ–°ç”ŸæŠ¥åˆ°éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ"
answer = rag_chain.invoke(query)

print(f"ç”¨æˆ·é—®é¢˜ï¼š{query}")
print(f"å›ç­”ï¼š{answer['result']}")
```

**ç”Ÿæˆå‚æ•°è¯´æ˜**ï¼š
- `temperature`ï¼šæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼ˆ0-1ï¼‰
  - 0ï¼šç¡®å®šæ€§è¾“å‡ºï¼Œé€‚åˆäº‹å®æ€§å›ç­”
  - 0.7ï¼šæœ‰ä¸€å®šåˆ›é€ æ€§ï¼Œé€‚åˆéœ€è¦æ¨ç†çš„åœºæ™¯
-  - 1ï¼šé«˜åº¦åˆ›é€ æ€§ï¼Œé€‚åˆåˆ›æ„å†™ä½œ

- `k`ï¼šæ£€ç´¢åˆ°çš„æ–‡æ¡£å—æ•°é‡
  - å¤ªå°‘ï¼šå¯èƒ½ä¿¡æ¯ä¸è¶³
  - å¤ªå¤šï¼šå¯èƒ½è¶…å‡º LLM ä¸Šä¸‹æ–‡çª—å£
  - æ¨èï¼š3-5ï¼Œæ ¹æ® LLM ä¸Šä¸‹æ–‡çª—å£è°ƒæ•´

- `chain_type`ï¼šæ£€ç´¢ç»“æœçš„ç»„åˆæ–¹å¼
  - `stuff`ï¼šç®€å•æ‹¼æ¥æ‰€æœ‰æ–‡æ¡£å—
  - `map_reduce`ï¼šåˆ†åˆ«å¤„ç†æ¯ä¸ªæ–‡æ¡£å—ï¼Œç„¶ååˆå¹¶ç»“æœ
  - `refine`ï¼šè¿­ä»£ä¼˜åŒ–å›ç­”

**ç”Ÿæˆä¼˜åŒ–å»ºè®®**ï¼š
1. **æ·»åŠ å¼•ç”¨**ï¼šåœ¨å›ç­”ä¸­æ·»åŠ æ¥æºæ–‡æ¡£çš„å¼•ç”¨
2. **å»é‡æ‘˜è¦**ï¼šå¯¹é‡å¤çš„æ–‡æ¡£å—è¿›è¡Œå»é‡
3. **ç›¸å…³æ€§è¿‡æ»¤**ï¼šåŸºäºç›¸ä¼¼åº¦åˆ†æ•°è¿‡æ»¤ä½ç›¸å…³æ–‡æ¡£
4. **ä¸Šä¸‹æ–‡ä¼˜åŒ–**ï¼šæ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´ä¸Šä¸‹æ–‡å¤§å°

## ğŸ“Š RAG æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·æŸ¥è¯¢   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç›¸ä¼¼åº¦æ£€ç´¢ â”‚
â”‚ (å‘é‡ç©ºé—´)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ–‡æ¡£æ’åº   â”‚
â”‚  (Top K)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸Šä¸‹æ–‡æ„å»º â”‚
â”‚ (æ‹¼æ¥/ç­›é€‰) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM ç”Ÿæˆ  â”‚
â”‚ (ç”Ÿæˆå›ç­”)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æœ€ç»ˆå›ç­”   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ åº”ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šçŸ¥è¯†é—®ç­”

**é—®é¢˜**ï¼š"æ–°ç”ŸæŠ¥åˆ°éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ"

**æµç¨‹**ï¼š
1. ç”¨æˆ·æå‡ºé—®é¢˜
2. RAG ç³»ç»Ÿæ£€ç´¢ç›¸å…³æ–‡æ¡£å—
3. LLM åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå›ç­”ï¼Œå¹¶åœ¨å›ç­”ä¸­æ·»åŠ å¼•ç”¨

**ç¤ºä¾‹è¾“å‡º**ï¼š
```
æ ¹æ®æ–°ç”ŸæŠ¥åˆ°æ‰‹å†Œï¼Œæ–°ç”ŸæŠ¥åˆ°éœ€è¦å‡†å¤‡ä»¥ä¸‹ææ–™ï¼š

1. å½•å–é€šçŸ¥ä¹¦
2. èº«ä»½è¯åŸä»¶åŠå¤å°ä»¶
3. é«˜è€ƒå‡†è€ƒè¯
4. è¿‘æœŸä¸€å¯¸å…å† ç…§ç‰‡ 8 å¼ 
5. å›¢å‘˜è¯åŠå…šç»„ç»‡å…³ç³»è¯æ˜ï¼ˆå¦‚æœ‰ï¼‰

[æ¥æºï¼šdocs/æ•™å­¦æ–‡ä»¶/ragfiles/2025å¹´æœ¬ç§‘æ–°ç”ŸæŠ¥åˆ°æ‰‹å†Œ.pdfï¼Œç¬¬ 5-10 é¡µ]
```

### åœºæ™¯ 2ï¼šæ”¿ç­–å’¨è¯¢

**é—®é¢˜**ï¼š"å­¦ç”Ÿè¿çºªæœ‰å“ªäº›å¤„ç½šè§„å®šï¼Ÿ"

**æµç¨‹**ï¼š
1. ç”¨æˆ·æå‡ºé—®é¢˜
2. RAG ç³»ç»Ÿæ£€ç´¢ç›¸å…³æ–‡æ¡£å—
3. LLM åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå›ç­”ï¼Œæ€»ç»“å¤„ç½šç§ç±»å’Œæ ‡å‡†

**ç¤ºä¾‹è¾“å‡º**ï¼š
```
æ ¹æ®ã€Šä¸œåå¤§å­¦å­¦ç”Ÿè¿çºªå¤„åˆ†è§„å®šã€‹ï¼Œå­¦ç”Ÿè¿çºªå¤„åˆ†åŒ…æ‹¬ä»¥ä¸‹ç±»å‹ï¼š

1. è­¦å‘Šï¼šå£å¤´æ‰¹è¯„ï¼Œè®°å½•åœ¨å­¦ç”Ÿæ¡£æ¡ˆ
2. ä¸¥é‡è­¦å‘Šï¼šä¹¦é¢è­¦å‘Šï¼Œè®°å½•åœ¨å­¦ç”Ÿæ¡£æ¡ˆ
3. è®°è¿‡ï¼šè®°è¿‡å¤„åˆ†ï¼Œè®°è¿‡å¤„åˆ†æœŸé™ä¸º 12 ä¸ªæœˆ
4. ç•™æ ¡å¯Ÿçœ‹ï¼šç•™æ ¡å¯Ÿçœ‹å¤„åˆ†ï¼Œè®°è¿‡å¤„åˆ†æœŸé™ä¸º 12 ä¸ªæœˆ
5. å¼€é™¤å­¦ç±ï¼šæœ€ä¸¥é‡çš„å¤„ç½šï¼Œä»…é€‚ç”¨äºä¸¥é‡è¿çºª

å¤„åˆ†æœŸé™ä»ä½œå‡ºå¤„åˆ†å†³å®šä¹‹æ—¥èµ·è®¡ç®—ã€‚åœ¨å¤„åˆ†æœŸé™å†…å†æ¬¡å—åˆ°å¤„åˆ†çš„ï¼Œå¤„åˆ†æœŸé™ä»å‰ä¸€å¤„åˆ†è§£é™¤ä¹‹æ—¥èµ·è®¡ç®—ã€‚

[æ¥æºï¼šdocs/æ•™å­¦æ–‡ä»¶/ragfiles/## ä¸œåå¤§å­¦å­¦ç”Ÿè¿çºªå¤„åˆ†è§„å®š.pdfï¼Œç¬¬ 3-8 é¡µ]
```

### åœºæ™¯ 3ï¼šå¤šè½®å¯¹è¯

**åœºæ™¯**ï¼šç”¨æˆ·å¯èƒ½æå‡ºä¸€ç³»åˆ—ç›¸å…³é—®é¢˜ï¼ŒRAG ç³»ç»Ÿéœ€è¦æ”¯æŒå¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡ç®¡ç†ã€‚

**å®ç°æ–¹å¼**ï¼š
1. ä½¿ç”¨ LangChain çš„ Memory ç»„ä»¶ä¿å­˜å¯¹è¯å†å²
2. åœ¨æ¯æ¬¡æ£€ç´¢æ—¶è€ƒè™‘ä¹‹å‰çš„å¯¹è¯å†å²
3. LLM åŸºäºå¯¹è¯å†å²å’Œæ£€ç´¢ç»“æœç”Ÿæˆå›ç­”

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# å®‰è£… RAG ç›¸å…³ä¾èµ–
uv pip install langchain langchain-core langchain-community chromadb sentence-transformers python-dotenv --index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

### 2. åŠ è½½å’Œåˆ‡åˆ†æ–‡æ¡£

```python
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# åŠ è½½æ–‡æ¡£
loader = PyPDFLoader("docs/æ•™å­¦æ–‡ä»¶/ragfiles/2025å¹´æœ¬ç§‘æ–°ç”ŸæŠ¥åˆ°æ‰‹å†Œ.pdf")
documents = loader.load()

# åˆ‡åˆ†æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", " ", ""]
)
splits = text_splitter.split_documents(documents)
```

### 3. åˆ›å»ºå‘é‡æ•°æ®åº“

```python
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma

# åˆå§‹åŒ– Embedding æ¨¡å‹
embedding = SentenceTransformerEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

# åˆ›å»ºå‘é‡æ•°æ®åº“
vector_store = Chroma.from_documents(
    documents=splits,
    embedding=embedding,
    persist_directory="./db/chroma_db",
    collection_name="campus_knowledge"
)

# æŒä¹…åŒ–åˆ°ç£ç›˜
vector_store.persist()
```

### 4. æ‰§è¡Œæ£€ç´¢

```python
# åŠ è½½å‘é‡æ•°æ®åº“
vector_store = Chroma(
    persist_directory="./db/chroma_db",
    embedding_function=embedding
)

# æ‰§è¡Œç›¸ä¼¼åº¦æ£€ç´¢
query = "æ–°ç”ŸæŠ¥åˆ°éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ"
results = vector_store.similarity_search(query, k=3)

for i, result in enumerate(results, 1):
    print(f"ç»“æœ {i}:")
    print(f"å†…å®¹ï¼š{result.page_content[:150]}...")
    print(f"æ¥æºï¼š{result.metadata}")
```

### 5. ç»“åˆ LLM ç”Ÿæˆå›ç­”

```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# åˆ›å»º LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# åˆ›å»º RAG é“¾
rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True
)

# æ‰§è¡ŒæŸ¥è¯¢
query = "æ–°ç”ŸæŠ¥åˆ°éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ"
answer = rag_chain.invoke(query)

print(f"ç”¨æˆ·é—®é¢˜ï¼š{query}")
print(f"å›ç­”ï¼š{answer['result']}")
```

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£
- LangChain æ–‡æ¡£ï¼šhttps://python.langchain.com/
- ChromaDB æ–‡æ¡£ï¼šhttps://docs.trychroma.com/
- Sentence-Transformers æ–‡æ¡£ï¼šhttps://www.sbert.net/

### æ¨èé˜…è¯»
- ã€ŠLangChain å®æˆ˜ã€‹
- ã€ŠRAGï¼šæ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯è¯¦è§£ã€‹
- ã€Šå‘é‡æ•°æ®åº“é€‰å‹æŒ‡å—ã€‹
- ã€Šå¤§è¯­è¨€æ¨¡å‹ RAG å®è·µæŒ‡å—ã€‹

---

**æ–‡æ¡£åˆ›å»ºæ—¶é—´**ï¼š2026-01-30
**æ–‡æ¡£ç»´æŠ¤è€…**ï¼šCampusFlow é¡¹ç›®ç»„
