"""
RAG åŸºç¡€åŠŸèƒ½æµ‹è¯•ï¼ˆä¸ä¾èµ–ä¸‹è½½æ¨¡å‹ï¼‰
æµ‹è¯•åŸºæœ¬çš„æ•°æ®ç»“æ„å’Œé€»è¾‘
"""

import sys
from pathlib import Path

# æµ‹è¯•å¯¼å…¥
print("=" * 50)
print("ğŸ§ª RAG åŸºç¡€åŠŸèƒ½æµ‹è¯•")
print("=" * 50)
print()

print("1. æµ‹è¯•æ–‡ä»¶ç»“æ„...")
print("-" * 50)

files_to_check = [
    "utils/rag_utils.py",
    "utils/rag_test_simple.py",
    "data/"
]

all_files_exist = True
for file_path in files_to_check:
    path = Path(file_path)
    exists = path.exists() or path.is_dir()
    status = "âœ…" if exists else "âŒ"
    print(f"{status} {file_path} {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}")
    if not exists:
        all_files_exist = False

print()

print("2. æµ‹è¯• Python å¯¼å…¥...")
print("-" * 50)

try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    print("âœ… langchain_text_splitters å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ langchain_text_splitters å¯¼å…¥å¤±è´¥: {e}")
    all_files_exist = False

try:
    from langchain_core.documents import Document
    print("âœ… langchain_core.documents å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ langchain_core.documents å¯¼å…¥å¤±è´¥: {e}")
    all_files_exist = False

try:
    import chromadb
    print(f"âœ… chromadb å¯¼å…¥æˆåŠŸ (ç‰ˆæœ¬: {chromadb.__version__})")
except ImportError as e:
    print(f"âŒ chromadb å¯¼å…¥å¤±è´¥: {e}")
    all_files_exist = False

print()

print("3. æµ‹è¯•æ–‡æ¡£åˆ‡åˆ†åŠŸèƒ½...")
print("-" * 50)

try:
    from langchain_core.documents import Document
    from langchain_text_splitters import RecursiveCharacterTextSplitter

    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_text = """
    æ ¡å›­æŠ¥åˆ°æ—¶é—´ï¼šæ¯å¹´ 9 æœˆ 1 æ—¥è‡³ 9 æœˆ 5 æ—¥ã€‚æŠ¥åˆ°åœ°ç‚¹ï¼šå­¦æ ¡ä¸»æ¥¼å¤§å…ã€‚
    æ‰€éœ€ææ–™ï¼šå½•å–é€šçŸ¥ä¹¦ã€èº«ä»½è¯åŸä»¶åŠå¤å°ä»¶ã€é«˜è€ƒå‡†è€ƒè¯ã€‚
    """

    documents = [Document(page_content=test_text)]
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=100,
        chunk_overlap=20,
        separators=["ã€‚", "ï¼Œ", "ã€‚", " "]
    )

    splits = splitter.split_documents(documents)
    print(f"âœ… æ–‡æ¡£åˆ‡åˆ†æˆåŠŸï¼š{len(splits)} ä¸ªæ–‡æœ¬å—")

    for i, split in enumerate(splits, 1):
        print(f"\næ–‡æœ¬å— {i}:")
        print(f"  {split.page_content[:80]}...")

except Exception as e:
    print(f"âŒ æ–‡æ¡£åˆ‡åˆ†å¤±è´¥: {e}")
    all_files_exist = False

print()

print("4. æµ‹è¯• Chroma åŸºæœ¬åŠŸèƒ½...")
print("-" * 50)

try:
    import chromadb

    # åˆ›å»ºå†…å­˜å®¢æˆ·ç«¯
    client = chromadb.Client()

    # åˆ›å»ºé›†åˆ
    collection = client.create_collection(
        name="test_collection",
        metadata={"hnsw:space": "cosine"}
    )

    # æ·»åŠ æµ‹è¯•æ•°æ®ï¼ˆä½¿ç”¨ç®€å•çš„æ–‡æœ¬ï¼Œä¸ä¾èµ– embeddingï¼‰
    collection.add(
        ids=["doc_1", "doc_2"],
        documents=["æµ‹è¯•æ–‡æ¡£ 1", "æµ‹è¯•æ–‡æ¡£ 2"],
        metadatas=[{"source": "test1"}, {"source": "test2"}]
    )

    print(f"âœ… Chroma é›†åˆåˆ›å»ºæˆåŠŸ")
    print(f"   é›†åˆåç§°: test_collection")
    print(f"   æ–‡æ¡£æ•°é‡: {collection.count()}")

    # æŸ¥è¯¢æµ‹è¯•
    results = collection.query(
        query_texts=["æµ‹è¯•"],
        n_results=1
    )

    if results['documents'] and results['documents'][0]:
        print(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ°ç»“æœ: {results['documents'][0][0]}")
    else:
        print("âš ï¸  æŸ¥è¯¢æœªè¿”å›ç»“æœ")

except Exception as e:
    print(f"âŒ Chroma åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
    all_files_exist = False

print()

print("=" * 50)
print("ğŸ“Š æµ‹è¯•æ€»ç»“")
print("=" * 50)

if all_files_exist:
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RAG åŸºç¡€åŠŸèƒ½æ­£å¸¸")
    sys.exit(0)
else:
    print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯")
    sys.exit(1)
