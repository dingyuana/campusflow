"""
RAG ç®€åŒ–æµ‹è¯•è„šæœ¬
ä½¿ç”¨æœ¬åœ°æµ‹è¯•æ•°æ®ï¼Œä¸ä¾èµ–ä¸‹è½½å¤§å‹æ¨¡å‹
"""

from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from chromadb.utils import embedding_functions
import chromadb


def test_chroma_basic():
    """æµ‹è¯• Chroma åŸºæœ¬åŠŸèƒ½"""

    print("=" * 50)
    print("ğŸš€ æµ‹è¯• Chroma å‘é‡åº“")
    print("=" * 50)
    print()

    # 1. å‡†å¤‡æµ‹è¯•æ–‡æ¡£
    sample_docs = [
        "æ ¡å›­æŠ¥åˆ°æ—¶é—´ï¼šæ¯å¹´ 9 æœˆ 1 æ—¥è‡³ 9 æœˆ 5 æ—¥ã€‚æŠ¥åˆ°åœ°ç‚¹ï¼šå­¦æ ¡ä¸»æ¥¼å¤§å…ã€‚æ‰€éœ€ææ–™ï¼šå½•å–é€šçŸ¥ä¹¦ã€èº«ä»½è¯åŸä»¶åŠå¤å°ä»¶ã€é«˜è€ƒå‡†è€ƒè¯ã€‚",
        "å®¿èˆå¼€æ”¾æ—¶é—´ï¼šæ¯å¤© 6:00 - 23:00ã€‚é—¨ç¦æ—¶é—´ï¼šæ™šä¸Š 23:00ã€‚å®¿èˆè®¾æ–½ï¼šæ¯ä¸ªå®¿èˆé…å¤‡ç©ºè°ƒã€ç‹¬ç«‹å«ç”Ÿé—´ã€ä¹¦æ¡Œå’Œè¡£æŸœã€‚",
        "å­¦åˆ†è¦æ±‚ï¼šæœ¬ç§‘ç”Ÿéœ€ä¿®æ»¡ 160 å­¦åˆ†æ–¹å¯æ¯•ä¸šã€‚è¯¾ç¨‹ç±»å‹ï¼šå…¬å…±åŸºç¡€è¯¾ï¼ˆçº¦ 40 å­¦åˆ†ï¼‰ã€ä¸“ä¸šåŸºç¡€è¯¾ï¼ˆçº¦ 60 å­¦åˆ†ï¼‰ã€‚",
        "å›½å®¶å¥–å­¦é‡‘ï¼šæ¯äººæ¯å¹´ 8000 å…ƒã€‚è¯„å®šæ¡ä»¶ï¼šç»¼åˆç´ è´¨æµ‹è¯„æˆç»©æ’ååœ¨å‰ 5%ã€æ— æŒ‚ç§‘è®°å½•ã€ç§¯æå‚ä¸ç¤¾ä¼šå®è·µæ´»åŠ¨ã€‚",
        "å›¾ä¹¦é¦†å¼€æ”¾æ—¶é—´ï¼šå‘¨ä¸€è‡³å‘¨äº” 8:00 - 22:00ã€‚å€Ÿé˜…è§„åˆ™ï¼šæœ¬ç§‘ç”Ÿæœ€å¤šå¯å€Ÿ 10 æœ¬å›¾ä¹¦ï¼Œå€Ÿé˜…æœŸé™ä¸º 30 å¤©ã€‚",
    ]

    print(f"âœ… å‡†å¤‡äº† {len(sample_docs)} ä¸ªæµ‹è¯•æ–‡æ¡£")
    print()

    # 2. åˆ‡åˆ†æ–‡æ¡£
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=200,
        chunk_overlap=20,
        separators=["ã€‚", "ï¼Œ", "ã€‚", " "]
    )

    documents = [Document(page_content=doc) for doc in sample_docs]
    splits = text_splitter.split_documents(documents)

    print(f"âœ… æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼š{len(splits)} ä¸ªæ–‡æœ¬å—")
    print()

    # 3. åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯ï¼ˆå†…å­˜æ¨¡å¼ï¼‰
    client = chromadb.Client()

    # 4. åˆ›å»ºé›†åˆ
    collection = client.create_collection(
        name="campus_knowledge_test",
        metadata={"hnsw:space": "cosine"}
    )

    print(f"âœ… åˆ›å»º Chroma é›†åˆæˆåŠŸ")
    print()

    # 5. å‡†å¤‡æ•°æ®
    ids = [f"doc_{i}" for i in range(len(splits))]
    texts = [split.page_content for split in splits]

    print(f"âœ… å‡†å¤‡å‘é‡æ•°æ®ï¼š{len(texts)} ä¸ª")
    print()

    # 6. æ·»åŠ æ–‡æ¡£ï¼ˆä¸ä½¿ç”¨ embeddingï¼Œä½¿ç”¨ç®€å•æ–‡æœ¬ï¼‰
    # æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒåº”è¯¥ä½¿ç”¨çœŸå®çš„ embedding æ¨¡å‹
    for i, text in enumerate(texts):
        collection.add(
            ids=[ids[i]],
            documents=[text],
            metadatas=[{"source": f"chunk_{i}"}]
        )

    print(f"âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸ")
    print()

    # 7. æµ‹è¯•æŸ¥è¯¢ï¼ˆä½¿ç”¨ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦ï¼‰
    test_queries = [
        "æ–°ç”ŸæŠ¥åˆ°éœ€è¦ä»€ä¹ˆææ–™ï¼Ÿ",
        "å®¿èˆå‡ ç‚¹å…³é—¨ï¼Ÿ",
        "å¥–å­¦é‡‘æ€ä¹ˆç”³è¯·ï¼Ÿ",
        "å›¾ä¹¦é¦†å¯ä»¥å€Ÿå‡ æœ¬ä¹¦ï¼Ÿ"
    ]

    print("=" * 50)
    print("ğŸ” æµ‹è¯•è¯­ä¹‰æœç´¢")
    print("=" * 50)
    print()

    for query in test_queries:
        print(f"ğŸ“ æŸ¥è¯¢ï¼š{query}")
        print("-" * 50)

        try:
            results = collection.query(
                query_texts=[query],
                n_results=2
            )

            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0], 1):
                    print(f"\nç»“æœ {i}:")
                    print(f"å†…å®¹: {doc[:100]}...")
            else:
                print("\næœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        except Exception as e:
            print(f"\næŸ¥è¯¢å‡ºé”™: {e}")

        print()

    print("=" * 50)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("=" * 50)
    print()
    print("ğŸ’¡ æ³¨æ„ï¼š")
    print("   - å½“å‰æµ‹è¯•ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼Œæœªä½¿ç”¨çœŸå®çš„ Embedding æ¨¡å‹")
    print("   - ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨ BAAI/bge-m3 æˆ–å…¶ä»– Embedding æ¨¡å‹")
    print("   - Chroma å‘é‡åº“å·²æˆåŠŸåˆ›å»ºå’Œæµ‹è¯•")


if __name__ == "__main__":
    test_chroma_basic()
