**课程周期**：10 天（核心实训）

**适用对象**：计算机 / AI 相关专业大三 / 大四学生（前置基础：Python 基础、简单 SQL、Git 基本使用）

**核心交付**：可公网访问的智慧校园多智能体系统（Vercel 部署）

---

## Day 1：项目启动与工程化初探

**一、前期知识（课前预习，1h）**

1. Git 基础操作（clone/commit/push/branch）；
2. 前后端分离项目的目录结构设计；
3. 云数据库（PostgreSQL）的基本概念（实例 / 表 / 连接）。

**二、实验目标**

1. 掌握企业级项目的工程化规范（Git Flow、目录结构）；
2. 完成项目初始化与云端环境（Vercel+PostgreSQL）搭建；
3. 实现本地与云端数据库的连接与基础数据操作。

**三、难点重点**

- **重点**：Git Flow 工作流落地、项目目录结构设计、云数据库连接；
- **难点**：Vercel 环境配置、数据库连接参数调试（避免因网络 / 权限导致连接失败）。

**四、知识基础**

- 必备：Python 虚拟环境使用（venv/conda）、SQL 基本查询语句；
- 可选：FastAPI 基础（无需深入，了解接口概念即可）。

**五、实验步骤（8h，含 2h 理论讲解）**

**阶段 1：理论讲解（2h）**

1. 多智能体系统（MAS）核心设计模式（15min）；
2. 分布式状态管理核心问题（15min）；
3. 工程化规范：Git Flow（主干 / 开发 / 特性分支）、Commit 规范（Conventional Commits）（30min）；
4. 项目目录结构设计（前后端分离、分层架构）（30min）；
5. Vercel+PostgreSQL 云环境搭建流程演示（30min）。

**阶段 2：实操落地（6h）**

**步骤 1：项目初始化（1.5h）**

1. 从实训沙盒模板创建 GitHub 仓库（提供模板地址）；
2. 克隆仓库到本地，创建 Python 虚拟环境：python -m venv venv，激活环境（Windows：venv\Scripts\activate；Mac/Linux：source venv/bin/activate）；
3. 安装依赖：pip install -r requirements.txt（依赖含：psycopg2-binary、fastapi、uvicorn、python-dotenv）；
4. 按标准目录结构创建文件夹：api/（接口）、agents/（智能体）、db/（数据库）、utils/（工具函数）、.env（环境变量）。

**步骤 2：Git 配置（1h）**

1. 创建开发分支：git checkout -b dev，再创建特性分支：git checkout -b feature/day1；
2. 配置.gitignore文件（添加venv/、.env、__pycache__/等）；
3. 编写 Commit 规范示例（如：feat: 初始化项目目录结构、docs: 添加README说明）。

**步骤 3：云端环境搭建（1.5h）**

1. 注册 / 登录 Vercel 账号，关联 GitHub 仓库；
2. 在 Vercel 中创建 PostgreSQL 实例（左侧导航→Storage→Create→PostgreSQL），记录连接信息（POSTGRES_URL、POSTGRES_USER、POSTGRES_PASSWORD、POSTGRES_DB）；
3. 在本地项目根目录创建.env文件，粘贴连接信息：

`POSTGRES_URL="postgresql://xxx:xxx@xxx.vercel-storage.com:5432/xxx"`

**步骤 4：数据库连接测试（1.5h）**

1. 在db/目录下创建[connect.py](http://connect.py/)，编写连接代码：

```python
import os
import psycopg2
from dotenv import load_dotenv

load_dotenv()


def connect_postgres():
    try:
        conn = psycopg2.connect(os.getenv("POSTGRES_URL"))
        cur = conn.cursor()
        print("数据库连接成功！")
        # 测试插入数据
        cur.execute("CREATE TABLE IF NOT EXISTS test (id SERIAL PRIMARY KEY, name VARCHAR(50))")
        cur.execute("INSERT INTO test (name) VALUES ('test_user')")
        conn.commit()
        # 测试查询
        cur.execute("SELECT * FROM test")
        print("查询结果：", cur.fetchall())
        cur.close()
        conn.close()
    except Exception as e:
        print("连接失败：", e)


if __name__ == "__main__":
    connect_postgres()
```

1. 运行脚本：python db/[connect.py](http://connect.py/)，确保输出 “数据库连接成功” 及查询结果；
2. 若失败，按错误提示调试（如：检查连接地址、网络权限、依赖安装）。

**步骤 5：代码提交与 PR（0.5h）**

1. 提交代码：git add . → git commit -m "feat: 完成项目初始化与PostgreSQL连接测试"；
2. 推送分支：git push origin feature/day1；
3. 在 GitHub 仓库创建 Pull Request（base: dev，compare: feature/day1），填写 PR 说明。

**六、考核方法（量化评分，10 分）**

| 考核项 | 分值 | 评分标准 |
| --- | --- | --- |
| 项目目录结构 | 2 分 | 符合标准结构（api/agents/db/utils），无冗余文件 |
| Git 配置 | 3 分 | 分支创建正确（dev/feature/day1），.gitignore 配置合理，Commit 规范 |
| 数据库连接 | 5 分 | 成功运行 connect.py，输出连接成功及查询结果，无报错 |
| 加分项 | 1 分 | 提交 PR 并填写规范说明，代码注释清晰 |

---

## Day 2：知识获取（RAG + 向量库）

**一、前期知识（课前预习，1h）**

1. RAG 核心流程（加载 - 切分 - 向量化 - 存储 - 检索）；
2. 向量库的基本概念（Embedding、相似度匹配）；
3. LangChain 的基础组件（Loader、Splitter、Embeddings）。

**二、实验目标**

1. 掌握语义切分的原则与实操方法；
2. 实现基于 Chroma 的向量库构建（文本加载→向量化→存储）；
3. 完成基础 RAG 检索（语义 / 关键词 / 混合检索）并验证效果。

**三、难点重点**

- **重点**：语义切分参数调整、Embedding 模型选择、RAG 检索流程；
- **难点**：语义切分后语义完整性保证、检索结果准确率优化。

**四、知识基础**

- 必备：Python 文件操作、JSON / 字典处理；
- 可选：NLP 基础（词向量概念，无需深入）。

**五、实验步骤（8h，含 2h 理论讲解）**

**阶段 1：理论讲解（2h）**

1. RAG 全流程解析（加载 - 切分 - 向量化 - 存储 - 检索 - 生成）（30min）；
2. 语义切分原则：chunk_size/chunk_overlap 配置逻辑，避免语义断裂（30min）；
3. 混合检索策略：关键词检索（精确匹配）+ 语义检索（模糊匹配）（20min）；
4. Chroma DB 特性与 LangChain 集成方法（20min）；
5. 开源 Embedding 模型选择（BGE-m3，轻量高效适配实训）（20min）。

**阶段 2：实操落地（6h）**

**步骤 1：环境准备（1h）**

1. 激活虚拟环境，安装新增依赖：pip install langchain langchain-core langchain-community chromadb sentence-transformers python-dotenv；
2. 下载实训提供的《校园报到手册》（PDF 文件），放入data/目录（新建 data 文件夹）。

**步骤 2：文本加载与语义切分（1.5h）**

1. 在utils/目录下创建[rag_utils.py](http://rag_utils.py/)，编写文本处理函数：

```python
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter


def load_and_split_doc():
    # 加载PDF
    loader = PyPDFLoader("data/校园报到手册.pdf")
    documents = loader.load()
    # 语义切分（chunk_size=500，chunk_overlap=50，可调整）
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    splits = text_splitter.split_documents(documents)
    print(f"切分后文本块数量：{len(splits)}")
    return splits


if __name__ == "__main__":
    load_and_split_doc()
```

1. 运行脚本：python utils/[rag_utils.py](http://rag_utils.py/)，查看切分后的文本块数量，手动检查前 3 个文本块，确保语义完整。

**步骤 3：向量化与 Chroma 存储（1.5h）**

1. 在[rag_utils.py](http://rag_utils.py/)中添加向量化与存储函数：

```python
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma


def init_chroma_db(splits):
    # 初始化开源Embedding模型（BGE-m3）
    embedding = SentenceTransformerEmbeddings(model_name="BAAI/bge-m3")
    # 创建Chroma向量库（本地存储，路径：db/chroma_db）
    db = Chroma.from_documents(
        documents=splits,
        embedding=embedding,
        persist_directory="db/chroma_db"
    )
    db.persist()
    print("Chroma向量库初始化完成！")
    return db


if __name__ == "__main__":
    splits = load_and_split_doc()
    init_chroma_db(splits)
```

1. 运行脚本，等待模型下载与向量库构建（首次运行较慢，耐心等待）；
2. 检查db/chroma_db目录，确认生成向量库文件（chroma.sqlite3 等）。

**步骤 4：基础检索实现（1.5h）**

1. 在[rag_utils.py](http://rag_utils.py/)中添加检索函数：

```python
def retrieve_from_chroma(query, k=3):
    # 加载已构建的Chroma向量库
    embedding = SentenceTransformerEmbeddings(model_name="BAAI/bge-m3")
    db = Chroma(
        persist_directory="db/chroma_db",
        embedding_function=embedding
    )
    # 1. 语义检索（相似度匹配）
    semantic_results = db.similarity_search(query, k=k)
    print("\n=== 语义检索结果 ===")
    for i, doc in enumerate(semantic_results):
        print(f"{i+1}. 内容：{doc.page_content[:100]}...")
        print(f"   来源：{doc.metadata}")
    # 2. 混合检索（关键词+语义，基于mmr重排序）
    hybrid_results = db.max_marginal_relevance_search(query, k=k, fetch_k=10)
    print("\n=== 混合检索结果 ===")
    for i, doc in enumerate(hybrid_results):
        print(f"{i+1}. 内容：{doc.page_content[:100]}...")
        print(f"   来源：{doc.metadata}")
    return semantic_results, hybrid_results


if __name__ == "__main__":
    splits = load_and_split_doc()
    db = init_chroma_db(splits)
    # 测试查询（例如："报到需要带什么材料？"）
    retrieve_from_chroma("报到需要带什么材料？")
```

1. 运行脚本，输入 3 个不同的测试查询（如报到材料、缴费标准、宿舍分配），对比语义检索与混合检索的结果差异；
2. 调整chunk_size/chunk_overlap参数，重新运行并观察检索结果变化（优化准确率）。

**步骤 5：代码提交与 PR（0.5h）**

1. 提交代码：git add . → git commit -m "feat: 完成RAG向量库构建与检索功能"；
2. 推送分支：git push origin feature/day2；
3. 创建 PR（base: dev，compare: feature/day2），附检索结果截图。

**六、考核方法（量化评分，10 分）**

| 考核项 | 分值 | 评分标准 |
| --- | --- | --- |
| 文本切分 | 2 分 | 切分参数合理，文本块语义完整，无断裂 |
| 向量库构建 | 3 分 | 成功生成 Chroma 向量库，无报错，文件完整 |
| 检索功能 | 4 分 | 实现语义 + 混合检索，测试 3 个查询均能返回相关结果 |
| 加分项 | 1 分 | 优化切分参数提升检索准确率，提交参数对比分析 |

---

## Day 3：复杂关系处理（知识图谱 Neo4j）

**一、前期知识（课前预习，1h）**

1. 图数据库核心概念（节点、边、属性）；
2. Cypher 查询语句基础（创建节点、创建关系、查询）；
3. 知识图谱建模原则（实体抽象、关系定义）。

**二、实验目标**

1. 掌握智慧校园场景的图建模方法；
2. 完成 Neo4j 知识图谱搭建（数据导入 + 可视化）；
3. 实现多跳查询与 Text-to-Cypher 功能。

**三、难点重点**

- **重点**：图模型设计、Cypher 脚本编写、多跳查询实现；
- **难点**：Text-to-Cypher 语句准确性、避免查询死循环。

**四、知识基础**

- 必备：SQL 查询逻辑、JSON 数据处理；
- 可选：图论基础（无需深入，了解 “关系” 概念即可）。

**五、实验步骤（8h，含 2h 理论讲解）**

**阶段 1：理论讲解（2h）**

1. 图数据库与关系型数据库的区别（适合复杂关系查询）（20min）；
2. 智慧校园图建模：核心实体（学生、教师、实验室、课程、院系）、关系（隶属、授课、选修、入驻）（30min）；
3. Cypher 语句详解：创建节点（CREATE）、创建关系（MATCH+CREATE）、查询（MATCH+RETURN）、多跳查询（MATCH ...-[]->...-[]->...）（30min）；
4. Neo4j Aura 云实例搭建与 LangChain 集成（20min）；
5. Text-to-Cypher 原理与错误处理（20min）。

**阶段 2：实操落地（6h）**

**步骤 1：Neo4j 环境搭建（1h）**

1. 注册 / 登录 Neo4j 账号，创建 Aura 免费实例（https://neo4j.com/aura/）；
2. 记录实例连接信息（URI、用户名、密码），放入.env文件：

```
NEO4J_URI="neo4j+s://xxx.databases.neo4j.io:7687"
NEO4J_USER="neo4j"
NEO4J_PASSWORD="xxx"
```

1. 安装 Neo4j 依赖：pip install neo4j langchain-openai（OpenAI 用于 Text-to-Cypher，可替换为开源模型）。

**步骤 2：图建模与数据导入（2h）**

1. 在db/目录下创建[neo4j_utils.py](http://neo4j_utils.py/)，编写 Cypher 导入脚本：

```python
from neo4j import GraphDatabase
import os
from dotenv import load_dotenv

load_dotenv()


class Neo4jGraph:
    def __init__(self):
        self.driver = GraphDatabase.driver(
            os.getenv("NEO4J_URI"),
            auth=(os.getenv("NEO4J_USER"), os.getenv("NEO4J_PASSWORD"))
        )

    def close(self):
        self.driver.close()

    def init_graph(self):
        # 1. 创建约束（避免重复节点）
        constraints = [
            "CREATE CONSTRAINT IF NOT EXISTS FOR (s:Student) REQUIRE s.id IS UNIQUE",
            "CREATE CONSTRAINT IF NOT EXISTS FOR (t:Teacher) REQUIRE t.id IS UNIQUE",
            "CREATE CONSTRAINT IF NOT EXISTS FOR (d:Department) REQUIRE d.name IS UNIQUE",
            "CREATE CONSTRAINT IF NOT EXISTS FOR (l:Laboratory) REQUIRE l.name IS UNIQUE",
            "CREATE CONSTRAINT IF NOT EXISTS FOR (c:Course) REQUIRE c.id IS UNIQUE"
        ]
        with self.driver.session() as session:
            for constraint in constraints:
                session.run(constraint)
            print("约束创建完成！")
            # 2. 导入仿真数据（节点+关系）
            cypher_script = """
            // 创建院系节点
            CREATE (d1:Department {name: '计算机学院', code: 'CS'}),
                   (d2:Department {name: '电子信息学院', code: 'EE'});
            // 创建教师节点
            CREATE (t1:Teacher {id: 'T001', name: '张三', title: '教授'}),
                   (t2:Teacher {id: 'T002', name: '李四', title: '副教授'});
            // 创建实验室节点
            CREATE (l1:Laboratory {name: '人工智能实验室', location: '科研楼A301'}),
                   (l2:Laboratory {name: '嵌入式实验室', location: '科研楼B202'});
            // 创建课程节点
            CREATE (c1:Course {id: 'C001', name: '大模型应用开发', credit: 3}),
                   (c2:Course {id: 'C002', name: '图数据库原理', credit: 2});
            // 创建学生节点
            CREATE (s1:Student {id: 'S001', name: '王五', grade: '大三'}),
                   (s2:Student {id: 'S002', name: '赵六', grade: '大四'});
            // 创建关系：院系-教师（隶属）
            MATCH (d:Department {name: '计算机学院'}), (t:Teacher) WHERE t.id IN ['T001', 'T002']
            CREATE (t)-[:BELONGS_TO]->(d);
            // 创建关系：教师-实验室（入驻）
            MATCH (t:Teacher {id: 'T001'}), (l:Laboratory {name: '人工智能实验室'})
            CREATE (t)-[:WORKS_IN]->(l);
            MATCH (t:Teacher {id: 'T002'}), (l:Laboratory {name: '嵌入式实验室'})
            CREATE (t)-[:WORKS_IN]->(l);
            // 创建关系：教师-课程（授课）
            MATCH (t:Teacher {id: 'T001'}), (c:Course {id: 'C001'})
            CREATE (t)-[:TEACHES]->(c);
            MATCH (t:Teacher {id: 'T002'}), (c:Course {id: 'C002'})
            CREATE (t)-[:TEACHES]->(c);
            // 创建关系：学生-课程（选修）
            MATCH (s:Student {id: 'S001'}), (c:Course) WHERE c.id IN ['C001', 'C002']
            CREATE (s)-[:TAKES]->(c);
            MATCH (s:Student {id: 'S002'}), (c:Course {id: 'C001'})
            CREATE (s)-[:TAKES]->(c);
            // 创建关系：学生-院系（隶属）
            MATCH (s:Student), (d:Department {name: '计算机学院'})
            CREATE (s)-[:BELONGS_TO]->(d);
            """
            session.run(cypher_script)
            print("知识图谱数据导入完成！")


if __name__ == "__main__":
    graph = Neo4jGraph()
    graph.init_graph()
    graph.close()
```

1. 运行脚本：python db/[neo4j_utils.py](http://neo4j_utils.py/)，无报错则导入成功；
2. 登录 Neo4j Aura 控制台，查看可视化图谱（左侧 “Graph” 标签），确认节点、边创建正确。

**步骤 3：多跳查询实现（1.5h）**

1. 在[neo4j_utils.py](http://neo4j_utils.py/)中添加查询函数：

```python
def multi_hop_query(self, query_type):
    """实现多跳查询"""
    with self.driver.session() as session:
        if query_type == 1:
            # 查询：计算机学院张老师的实验室里的学生（3跳：学生-课程-教师-实验室）
            cypher = """
            MATCH (s:Student)-[:TAKES]->(c:Course)-[:TEACHES]->(t:Teacher)-[:WORKS_IN]->(l:Laboratory)
            WHERE t.name = '张三' AND s-[:BELONGS_TO]->(:Department {name: '计算机学院'})
            RETURN s.name AS 学生姓名, l.name AS 实验室名称
            """
        elif query_type == 2:
            # 查询：选修大模型课程的学生所属院系（2跳：学生-课程，学生-院系）
            cypher = """
            MATCH (s:Student)-[:TAKES]->(c:Course {name: '大模型应用开发'}), (s)-[:BELONGS_TO]->(d:Department)
            RETURN s.name AS 学生姓名, d.name AS 院系名称
            """
        elif query_type == 3:
            # 查询：人工智能实验室的教师授课的课程（2跳：实验室-教师-课程）
            cypher = """
            MATCH (l:Laboratory {name: '人工智能实验室'})<-[:WORKS_IN]-(t:Teacher)-[:TEACHES]->(c:Course)
            RETURN t.name AS 教师姓名, c.name AS 课程名称
            """
        else:
            return "无效查询类型"
        result = session.run(cypher)
        return [dict(record) for record in result]


# 测试多跳查询
if __name__ == "__main__":
    graph = Neo4jGraph()
    # 测试3种多跳查询
    print("=== 多跳查询1结果 ===")
    print(graph.multi_hop_query(1))
    print("\n=== 多跳查询2结果 ===")
    print(graph.multi_hop_query(2))
    print("\n=== 多跳查询3结果 ===")
    print(graph.multi_hop_query(3))
    graph.close()
```

1. 运行脚本，查看 3 种多跳查询结果，确保返回正确；
2. 自定义 1 个多跳查询（如 “查询嵌入式实验室教师的学生”），添加到函数中并测试。

**步骤 4：Text-to-Cypher 实现（1h）**

1. 在[neo4j_utils.py](http://neo4j_utils.py/)中添加 Text-to-Cypher 函数（使用 LangChain）：

```python
from langchain.chains import GraphCypherQAChain
from langchain_openai import ChatOpenAI


def text_to_cypher(self, natural_query):
    """自然语言转Cypher查询"""
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)  # 可替换为开源模型
    chain = GraphCypherQAChain.from_llm(
        llm,
        graph=self.driver,
        verbose=True,
        return_intermediate_steps=True  # 输出Cypher语句，便于调试
    )
    try:
        result = chain({"query": natural_query})
        print(f"生成的Cypher语句：{result['intermediate_steps'][0]['query']}")
        print(f"查询结果：{result['result']}")
        return result
    except Exception as e:
        print(f"Text-to-Cypher失败：{e}")
        return {"error": str(e)}


# 测试Text-to-Cypher
if __name__ == "__main__":
    graph = Neo4jGraph()
    # 测试自然语言查询："张三老师教哪些课程？"
    graph.text_to_cypher("张三老师教哪些课程？")
    graph.close()
```

1. 配置 OpenAI API 密钥（放入.env：OPENAI_API_KEY="xxx"），运行脚本；
2. 查看生成的 Cypher 语句是否正确，查询结果是否符合预期；
3. 测试 2 个不同的自然语言查询，添加错误处理（如无效查询的兜底回复）。

**步骤 5：代码提交与 PR（0.5h）**

1. 提交代码：git add . → git commit -m "feat: 完成Neo4j知识图谱搭建与多跳查询/Text-to-Cypher"；
2. 推送分支：git push origin feature/day3；
3. 创建 PR，附 Neo4j 可视化截图和查询结果截图。

**六、考核方法（量化评分，10 分）**

| 考核项 | 分值 | 评分标准 |
| --- | --- | --- |
| 图模型与数据导入 | 3 分 | 节点 / 边创建正确，约束合理，无重复数据 |
| 多跳查询 | 3 分 | 实现 3 种基础多跳查询，结果准确；自定义 1 个查询并成功运行 |
| Text-to-Cypher | 3 分 | 自然语言转 Cypher 语句准确，2 个测试查询结果正确 |
| 加分项 | 1 分 | 添加 Text-to-Cypher 错误处理，避免死循环 / 无效语句 |

---

## Day 4：业务数据库设计（PostgreSQL）

**一、前期知识（课前预习，1h）**

1. 关系型数据库设计原则（三大范式）；
2. SQL 表设计（字段类型、主键、外键、索引）；
3. FastAPI 接口开发基础（路径操作、请求 / 响应模型）。

**二、实验目标**

1. 掌握智慧校园核心业务表的设计方法；
2. 完成 PostgreSQL 业务表创建与数据导入；
3. 实现基于 FastAPI 的业务接口开发与测试。

**三、难点重点**

- **重点**：业务表设计（符合三大范式）、FastAPI 分层开发（DAO/Service/API）；
- **难点**：表之间的关联关系设计、接口的幂等性与错误处理。

**四、知识基础**

- 必备：SQL 创建表（CREATE TABLE）、插入（INSERT）、查询（SELECT）语句；
- 可选：Python 类与函数、JSON 数据格式。

**五、实验步骤（8h，含 2h 理论讲解）**

**阶段 1：理论讲解（2h）**

1. 关系型数据库设计三大范式（避免冗余、保证数据一致性）（30min）；
2. 智慧校园核心业务表分析：学籍（student_records）、财务（payments）、宿舍（dormitory）（30min）；
3. 字段类型选择与索引设计（主键索引、外键索引、联合索引）（20min）；
4. FastAPI 分层开发：DAO（数据访问层）、Service（业务逻辑层）、API（接口层）（30min）；
5. 接口测试工具（Swagger UI、Postman）使用方法（10min）。

**阶段 2：实操落地（6h）**

**步骤 1：业务表设计与创建（1.5h）**

1. 在db/目录下创建[models.py](http://models.py/)，定义业务表 SQL：

```python
import psycopg2
from dotenv import load_dotenv
import os

load_dotenv()


def create_business_tables():
    """创建核心业务表：student_records（学籍）、payments（财务）、dormitory（宿舍）"""
    conn = None
    try:
        conn = psycopg2.connect(os.getenv("POSTGRES_URL"))
        cur = conn.cursor()
        # 1. 学籍表（student_records）
        cur.execute("""
        CREATE TABLE IF NOT EXISTS student_records (
            student_id VARCHAR(20) PRIMARY KEY,
            name VARCHAR(50) NOT NULL,
            gender VARCHAR(10),
            grade VARCHAR(10) NOT NULL,
            department VARCHAR(50) NOT NULL,
            admission_date DATE NOT NULL,
            status VARCHAR(20) DEFAULT 'active',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """)
        # 2. 财务表（payments）
        cur.execute("""
        CREATE TABLE IF NOT EXISTS payments (
            payment_id SERIAL PRIMARY KEY,
            student_id VARCHAR(20) NOT NULL,
            amount DECIMAL(10, 2) NOT NULL,
            payment_type VARCHAR(30) NOT NULL,  -- 学费/住宿费/其他
            status VARCHAR(20) DEFAULT 'unpaid',  -- unpaid/paid
            payment_date DATE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (student_id) REFERENCES student_records(student_id) ON DELETE CASCADE
        );
        """)
        # 3. 宿舍表（dormitory）
        cur.execute("""
        CREATE TABLE IF NOT EXISTS dormitory (
            dorm_id VARCHAR(20) PRIMARY KEY,
            student_id VARCHAR(20) UNIQUE NOT NULL,
            building VARCHAR(20) NOT NULL,
            floor INT NOT NULL,
            room_number VARCHAR(10) NOT NULL,
            bed_number INT NOT NULL,
            check_in_date DATE NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (student_id) REFERENCES student_records(student_id) ON DELETE CASCADE
        );
        """)
        # 添加索引（优化查询）
        cur.execute("CREATE INDEX IF NOT EXISTS idx_payments_student_id ON payments(student_id);")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_dormitory_student_id ON dormitory(student_id);")
        conn.commit()
        print("业务表创建完成！")
        cur.close()
    except Exception as e:
        print(f"创建业务表失败：{e}")
        if conn:
            conn.rollback()
    finally:
        if conn:
            conn.close()


if __name__ == "__main__":
    create_business_tables()
```

1. 运行脚本：python db/[models.py](http://models.py/)，无报错则表创建成功；
2. 登录 Vercel PostgreSQL 控制台，验证表结构是否正确。

**步骤 2：仿真数据导入（1h）**

1. 在db/目录下创建[seed_data.py](http://seed_data.py/)，编写数据导入脚本：

```python
import psycopg2
from dotenv import load_dotenv
import os
from datetime import date

load_dotenv()


def seed_business_data():
    """导入业务表仿真数据"""
    conn = None
    try:
        conn = psycopg2.connect(os.getenv("POSTGRES_URL"))
        cur = conn.cursor()
        # 导入学籍数据
        student_data = [
            ("S001", "王五", "男", "大三", "计算机学院", date(2022, 9, 1), "active"),
            ("S002", "赵六", "女", "大四", "计算机学院", date(2021, 9, 1), "active"),
            ("S003", "孙七", "男", "大三", "电子信息学院", date(2022, 9, 1), "active"),
            ("S004", "周八", "女", "大二", "计算机学院", date(2023, 9, 1), "active")
        ]
        cur.executemany("""
        INSERT INTO student_records (student_id, name, gender, grade, department, admission_date, status)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (student_id) DO NOTHING;
        """, student_data)
        # 导入财务数据
        payment_data = [
            ("S001", 8000.00, "学费", "paid", date(2024, 9, 5)),
            ("S001", 1200.00, "住宿费", "unpaid", None),
            ("S002", 8000.00, "学费", "paid", date(2024, 9, 3)),
            ("S002", 1200.00, "住宿费", "paid", date(2024, 9, 3)),
            ("S003", 8000.00, "学费", "unpaid", None),
            ("S004", 8000.00, "学费", "paid", date(2024, 9, 10))
        ]
        cur.executemany("""
        INSERT INTO payments (student_id, amount, payment_type, status, payment_date)
        VALUES (%s, %s, %s, %s, %s)
        ON CONFLICT DO NOTHING;
        """, payment_data)
        # 导入宿舍数据
        dorm_data = [
            ("D001", "S001", "1号宿舍楼", 3, "302", 1, date(2022, 9, 10)),
            ("D002", "S002", "2号宿舍楼", 4, "401", 2, date(2021, 9, 10)),
            ("D003", "S003", "3号宿舍楼", 2, "205", 3, date(2022, 9, 10)),
            ("D004", "S004", "1号宿舍楼", 1, "103", 4, date(2023, 9, 10))
        ]
        cur.executemany("""
        INSERT INTO dormitory (dorm_id, student_id, building, floor, room_number, bed_number, check_in_date)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (dorm_id) DO NOTHING;
        """, dorm_data)
        conn.commit()
        print("业务表仿真数据导入完成！")
        cur.close()
    except Exception as e:
        print(f"数据导入失败：{e}")
        if conn:
            conn.rollback()
    finally:
        if conn:
            conn.close()


if __name__ == "__main__":
    seed_business_data()
```

1. 运行脚本：python db/[seed_data.py](http://seed_data.py/)，无报错则数据导入成功；
2. 编写查询脚本验证数据：SELECT * FROM student_records;，确认数据正确。

**步骤 3：FastAPI 分层开发（DAO/Service）（1.5h）**

1. 在api/目录下创建dao/（数据访问层），创建[student_dao.py](http://student_dao.py/)：

```python
import psycopg2
from dotenv import load_dotenv
import os
from typing import List, Dict, Optional

load_dotenv()


class StudentDAO:
    """学生相关数据访问层"""

    def __connect(self):
        return psycopg2.connect(os.getenv("POSTGRES_URL"))

    def get_student_by_id(self, student_id: str) -> Optional[Dict]:
        """根据学生ID查询学籍信息"""
        conn = self.__connect()
        try:
            cur = conn.cursor()
            cur.execute("""
            SELECT student_id, name, gender, grade, department, admission_date, status
            FROM student_records
            WHERE student_id = %s;
            """, (student_id,))
            row = cur.fetchone()
            if not row:
                return None
            columns = [desc[0] for desc in cur.description]
            return dict(zip(columns, row))
        finally:
            conn.close()

    def get_student_payments(self, student_id: str) -> List[Dict]:
        """查询学生缴费记录"""
        conn = self.__connect()
        try:
            cur = conn.cursor()
            cur.execute("""
            SELECT payment_id, amount, payment_type, status, payment_date
            FROM payments
            WHERE student_id = %s;
            """, (student_id,))
            rows = cur.fetchall()
            columns = [desc[0] for desc in cur.description]
            return [dict(zip(columns, row)) for row in rows]
        finally:
            conn.close()

    def get_student_dormitory(self, student_id: str) -> Optional[Dict]:
        """查询学生宿舍信息"""
        conn = self.__connect()
        try:
            cur = conn.cursor()
            cur.execute("""
            SELECT dorm_id, building, floor, room_number, bed_number, check_in_date
            FROM dormitory
            WHERE student_id = %s;
            """, (student_id,))
            row = cur.fetchone()
            if not row:
                return None
            columns = [desc[0] for desc in cur.description]
            return dict(zip(columns, row))
        finally:
            conn.close()
```

1. 在api/目录下创建services/（业务逻辑层），创建[student_service.py](http://student_service.py/)：

```python
from api.dao.student_dao import StudentDAO
from typing import Dict, Optional, List


class StudentService:
    """学生相关业务逻辑层"""

    def __init__(self):
        self.dao = StudentDAO()

    def get_student_profile(self, student_id: str) -> Optional[Dict]:
        """获取学生完整档案（学籍+缴费+宿舍）"""
        student = self.dao.get_student_by_id(student_id)
        if not student:
            return None
        payments = self.dao.get_student_payments(student_id)
        dormitory = self.dao.get_student_dormitory(student_id)
        return {
            "student_info": student,
            "payments": payments,
            "dormitory": dormitory
        }

    def check_payment_status(self, student_id: str, payment_type: str = "住宿费") -> Dict:
        """检查特定类型缴费状态"""
        payments = self.dao.get_student_payments(student_id)
        target_payment = next((p for p in payments if p["payment_type"] == payment_type), None)
        if not target_payment:
            return {"status": "not_found", "message": f"未找到{payment_type}记录"}
        return {
            "status": target_payment["status"],
            "amount": target_payment["amount"],
            "payment_date": target_payment["payment_date"]
        }
```

**步骤 4：FastAPI 接口开发（1.5h）**

1. 在api/目录下创建[main.py](http://main.py/)（接口入口）：

```python
from fastapi import FastAPI, HTTPException, Query
from api.services.student_service import StudentService
from pydantic import BaseModel
from typing import Optional

app = FastAPI(title="智慧校园业务接口", version="1.0")
service = StudentService()


# 响应模型
class StudentProfileResponse(BaseModel):
    student_info: dict
    payments: list
    dormitory: Optional[dict]


class PaymentStatusResponse(BaseModel):
    status: str
    amount: Optional[float]
    payment_date: Optional[str]
    message: Optional[str]


@app.get("/api/student/{student_id}", response_model=StudentProfileResponse, summary="获取学生完整档案")
def get_student_profile(student_id: str):
    """根据学生ID获取学籍、缴费、宿舍信息"""
    profile = service.get_student_profile(student_id)
    if not profile:
        raise HTTPException(status_code=404, detail=f"学生ID {student_id} 不存在")
    return profile


@app.get("/api/student/{student_id}/payment", response_model=PaymentStatusResponse, summary="检查缴费状态")
def check_payment_status(student_id: str, payment_type: str = Query("住宿费", description="缴费类型")):
    """检查学生特定类型的缴费状态（默认：住宿费）"""
    status = service.check_payment_status(student_id, payment_type)
    if status["status"] == "not_found":
        raise HTTPException(status_code=404, detail=status["message"])
    return status


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api.main:app", host="0.0.0.0", port=8000, reload=True)
```

1. 运行接口服务：python api/[main.py](http://main.py/)，启动成功后访问http://127.0.0.1:8000/docs（Swagger UI）；
2. 在 Swagger UI 中测试接口：
- 测试/api/student/S001：返回完整档案；
- 测试/api/student/S001/payment：检查住宿费状态；
- 测试不存在的学生 ID（如 S999）：返回 404 错误。

**步骤 5：代码提交与 PR（0.5h）**

1. 提交代码：git add . → git commit -m "feat: 完成PostgreSQL业务表设计与FastAPI接口开发"；
2. 推送分支：git push origin feature/day4；
3. 创建 PR，附 Swagger UI 接口测试截图。

**六、考核方法（量化评分，10 分）**

| 考核项 | 分值 | 评分标准 |
| --- | --- | --- |
| 业务表设计 | 3 分 | 符合三大范式，字段类型合理，索引设计正确 |
| 数据导入 | 2 分 | 仿真数据导入成功，查询验证无问题 |
| FastAPI 接口 | 4 分 | 实现 2 个核心接口，Swagger UI 测试通过（存在 / 不存在的学生 ID 均正常响应） |
| 加分项 | 1 分 | 接口添加请求参数校验、响应模型规范，代码分层清晰（DAO/Service/API） |

---

## Day 5：LangGraph 状态持久化（Checkpointer）

**一、前期知识（课前预习，1h）**

1. LangGraph 核心概念（状态机、节点、边、State 对象）；
2. 状态持久化的核心意义（断点续传、状态恢复）；
3. PostgreSQL Checkpointer（PostgresSaver）工作原理。

**二、实验目标**

1. 掌握 LangGraph 状态机的基础开发方法；
2. 实现基于 PostgresSaver 的状态持久化；
3. 完成断点续传功能（断开重连，进度不丢失）。

**三、难点重点**

- **重点**：State 对象设计、PostgresSaver 配置、Thread ID 关联；
- **难点**：状态恢复逻辑、Thread ID 唯一性保证、状态过期清理。

**四、知识基础**

- 必备：Python 类与字典、LangChain 基础组件；
- 可选：状态机设计思想（无需深入，了解 “状态流转” 即可）。

**五、实验步骤（8h，含 2h 理论讲解）**

**阶段 1：理论讲解（2h）**

1. LangGraph 状态机原理：State 对象（状态载体）、节点（执行逻辑）、边（流转规则）（30min）；
2. 状态持久化的必要性：断点续传、多端同步、日志追溯（20min）；
3. Checkpointer 核心组件：PostgresSaver（存储状态到 PostgreSQL）、Thread ID（会话唯一标识）（30min）；
4. 状态恢复逻辑：根据 Thread ID 加载历史 State，继续执行流程（20min）；
5. 状态管理优化：过期清理、冗余数据删除（20min）。

**阶段 2：实操落地（6h）**

**步骤 1：环境准备（1h）**

1. 安装 LangGraph 依赖：pip install langgraph langchain-checkpoint-postgres；
2. 确保 PostgreSQL 连接正常（.env中 POSTGRES_URL 配置正确）。

**步骤 2：LangGraph 基础状态机开发（1.5h）**

1. 在agents/目录下创建[langgraph_basic.py](http://langgraph_basic.py/)，编写基础状态机：

```python
from langgraph.graph import StateGraph
from typing import List, Dict, Optional
from pydantic import BaseModel


# 1. 定义State对象（包含会话ID、对话历史、当前步骤、用户信息）
class CampusState(BaseModel):
    thread_id: str  # 会话唯一标识
    messages: List[Dict]  # 对话历史
    current_step: str = "start"  # 当前步骤（start/identity_confirm/payment_check/dorm_query/end）
    student_id: Optional[str] = None  # 学生ID（身份确认后赋值）


# 2. 定义节点函数（执行逻辑）
def start_node(state: CampusState) -> CampusState:
    """起始节点：引导用户进行身份确认"""
    state.messages.append({
        "role": "assistant",
        "content": "欢迎使用智慧校园报到系统！请提供你的学生ID进行身份确认～"
    })
    state.current_step = "identity_confirm"
    return state


def identity_confirm_node(state: CampusState) -> CampusState:
    """身份确认节点：获取学生ID，模拟验证"""
    # 从用户消息中提取学生ID（简化：直接取最后一条消息内容）
    user_msg = state.messages[-1]["content"]
    state.student_id = user_msg.strip()  # 假设用户直接输入学生ID（如S001）
    # 模拟身份验证成功（实际应调用Day4的FastAPI接口）
    state.messages.append({
        "role": "assistant",
        "content": f"身份确认成功！你是{state.student_id}号学生，接下来将为你办理报到流程～"
    })
    state.current_step = "payment_check"
    return state


# 3. 构建基础状态机（无持久化）
def build_basic_graph():
    graph = StateGraph(CampusState)
    # 添加节点
    graph.add_node("start", start_node)
    graph.add_node("identity_confirm", identity_confirm_node)
    # 添加边（流转规则）
    graph.set_entry_point("start")
    graph.add_edge("start", "identity_confirm")
    graph.add_edge("identity_confirm", "payment_check")  # 后续将扩展payment_check节点
    # 编译状态机
    return graph.compile()


# 测试基础状态机
if __name__ == "__main__":
    graph = build_basic_graph()
    # 初始化状态
    initial_state = CampusState(
        thread_id="thread_001",
        messages=[{"role": "user", "content": "开始报到"}]
    )
    # 执行状态机
    result = graph.invoke(initial_state)
    print("基础状态机执行结果：")
    for msg in result.messages:
        print(f"{msg['role']}: {msg['content']}")
    print(f"当前步骤：{result.current_step}")
    print(f"学生ID：{result.student_id}")
```

1. 运行脚本，测试基础状态机流转（start→identity_confirm），确认输出正确；
2. 观察 State 对象的变化，理解 “状态流转” 逻辑。

**步骤 3：PostgresSaver 配置与状态持久化（1.5h）**

1. 在agents/目录下创建[langgraph_checkpoint.py](http://langgraph_checkpoint.py/)，配置 PostgresSaver：

```python
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.graph import StateGraph
from dotenv import load_dotenv
import os
from agents.langgraph_basic import CampusState, start_node, identity_confirm_node

load_dotenv()


# 1. 配置PostgresSaver（连接PostgreSQL，存储状态）
def init_postgres_checkpointer() -> PostgresSaver:
    return PostgresSaver.from_conn_string(
        conn_string=os.getenv("POSTGRES_URL"),
        table_name="langgraph_checkpoints"  # 状态存储表（自动创建）
    )


# 2. 构建带持久化的状态机
def build_persistent_graph():
    checkpointer = init_postgres_checkpointer()
    graph = StateGraph(CampusState)
    # 添加节点（复用基础状态机的节点）
    graph.add_node("start", start_node)
    graph.add_node("identity_confirm", identity_confirm_node)
    # 添加边
    graph.set_entry_point("start")
    graph.add_edge("start", "identity_confirm")
    # 编译状态机（启用checkpointer）
    return graph.compile(checkpointer=checkpointer)


# 测试状态持久化（首次执行：存储状态）
if __name__ == "__main__":
    graph = build_persistent_graph()
    thread_id = "thread_001"  # 会话唯一ID
    # 初始化状态
    initial_state = CampusState(
        thread_id=thread_id,
        messages=[{"role": "user", "content": "开始报到"}]
    )
    # 执行状态机（首次执行，存储状态到PostgreSQL）
    result = graph.invoke(initial_state, config={"configurable": {"thread_id": thread_id}})
    print("首次执行结果：")
    for msg in result.messages:
        print(f"{msg['role']}: {msg['content']}")
    print(f"当前步骤：{result.current_step}")  # 应为identity_confirm
```

1. 运行脚本，首次执行状态机，存储状态到 PostgreSQL；
2. 登录 Vercel PostgreSQL 控制台，查看langgraph_checkpoints表，确认状态数据已存储。

**步骤 4：断点续传功能实现（1.5h）**

1. 在[langgraph_checkpoint.py](http://langgraph_checkpoint.py/)中添加状态恢复与断点续传测试：

```python
# 新增payment_check节点（模拟缴费检查步骤）
def payment_check_node(state: CampusState) -> CampusState:
    """缴费检查节点：模拟查询住宿费状态"""
    state.messages.append({
        "role": "assistant",
        "content": f"正在查询{state.student_id}的住宿费缴费状态...\n查询结果：未缴费，请完成缴费后继续～"
    })
    state.current_step = "dorm_query"
    return state


# 更新带持久化的状态机（添加payment_check节点）
def build_persistent_graph():
    checkpointer = init_postgres_checkpointer()
    graph = StateGraph(CampusState)
    # 添加节点
    graph.add_node("start", start_node)
    graph.add_node("identity_confirm", identity_confirm_node)
    graph.add_node("payment_check", payment_check_node)  # 新增节点
    # 添加边
    graph.set_entry_point("start")
    graph.add_edge("start", "identity_confirm")
    graph.add_edge("identity_confirm", "payment_check")
    graph.add_edge("payment_check", "dorm_query")
    # 编译状态机
    return graph.compile(checkpointer=checkpointer)
```