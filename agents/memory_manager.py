"""
Day 6: è®°å¿†ç®¡ç†æ¨¡å—
å®ç°çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†
"""

from typing import List, Dict, Any, Optional
from langchain_core.messages import BaseMessage
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from dotenv import load_dotenv
import os

load_dotenv()


class ShortTermMemory:
    """çŸ­æœŸè®°å¿†ç®¡ç†å™¨ï¼ˆåŸºäº Stateï¼‰"""

    def __init__(self, max_messages: int = 10):
        """
        åˆå§‹åŒ–çŸ­æœŸè®°å¿†

        Args:
            max_messages: æœ€å¤šä¿ç•™çš„æ¶ˆæ¯æ•°é‡
        """
        self.max_messages = max_messages

    def add_message(self, messages: List[BaseMessage], new_message: BaseMessage) -> List[BaseMessage]:
        """
        æ·»åŠ æ–°æ¶ˆæ¯åˆ°çŸ­æœŸè®°å¿†

        Args:
            messages: å½“å‰æ¶ˆæ¯åˆ—è¡¨
            new_message: æ–°æ¶ˆæ¯

        Returns:
            æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        updated_messages = messages + [new_message]

        # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
        if len(updated_messages) > self.max_messages:
            updated_messages = updated_messages[-self.max_messages:]

        return updated_messages

    def get_recent_context(self, messages: List[BaseMessage], limit: int = 5) -> str:
        """
        è·å–æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            limit: è¿”å›çš„æ¶ˆæ¯æ•°é‡

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        recent_messages = messages[-limit:] if messages else []

        context = ""
        for msg in recent_messages:
            role = "ç”¨æˆ·" if msg.type == "human" else "åŠ©æ‰‹"
            context += f"{role}: {msg.content}\n"

        return context


class LongTermMemory:
    """é•¿æœŸè®°å¿†ç®¡ç†å™¨ï¼ˆåŸºäº Chroma å‘é‡åº“ï¼‰"""

    def __init__(self, persist_directory: str = "./db/experience_memory"):
        """
        åˆå§‹åŒ–é•¿æœŸè®°å¿†

        Args:
            persist_directory: æŒä¹…åŒ–ç›®å½•
        """
        self.persist_directory = persist_directory
        self.embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-m3",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        self.vector_store = None

    def initialize(self):
        """åˆå§‹åŒ–æˆ–åŠ è½½é•¿æœŸè®°å¿†å‘é‡åº“"""
        from pathlib import Path

        if Path(self.persist_directory).exists():
            print(f"âœ… åŠ è½½é•¿æœŸè®°å¿†: {self.persist_directory}")
            self.vector_store = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings,
                collection_name="experience_memory"
            )
        else:
            print(f"âœ… åˆ›å»ºé•¿æœŸè®°å¿†: {self.persist_directory}")
            # åˆ›å»ºç©ºå‘é‡åº“ï¼ˆæ·»åŠ ä¸€ä¸ªè™šæ‹Ÿæ–‡æ¡£ï¼‰
            from langchain_core.documents import Document
            dummy_doc = Document(page_content="åˆå§‹åŒ–", metadata={"type": "init"})
            self.vector_store = Chroma.from_documents(
                documents=[dummy_doc],
                embedding=self.embeddings,
                persist_directory=self.persist_directory,
                collection_name="experience_memory"
            )

    def add_experience(self, query: str, answer: str, context: Dict[str, Any] = None):
        """
        æ·»åŠ ç»éªŒåˆ°é•¿æœŸè®°å¿†

        Args:
            query: ç”¨æˆ·é—®é¢˜
            answer: ç³»ç»Ÿå›ç­”
            context: é™„åŠ çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        from langchain_core.documents import Document

        # åˆ›å»ºç»éªŒæ–‡æ¡£
        content = f"é—®é¢˜: {query}\nå›ç­”: {answer}"
        metadata = {
            "type": "experience",
            "query": query,
            "answer": answer
        }

        if context:
            metadata.update(context)

        document = Document(page_content=content, metadata=metadata)

        # æ·»åŠ åˆ°å‘é‡åº“
        self.vector_store.add_documents([document])
        self.vector_store.persist()

        print(f"âœ… ç»éªŒå·²æ·»åŠ åˆ°é•¿æœŸè®°å¿†: {query[:50]}...")

    def retrieve_relevant_experiences(self, query: str, k: int = 3) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸å…³ç»éªŒ

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›çš„ç»éªŒæ•°é‡

        Returns:
            ç›¸å…³ç»éªŒåˆ—è¡¨
        """
        results = self.vector_store.similarity_search(query, k=k)

        experiences = []
        for doc in results:
            experiences.append({
                "content": doc.page_content,
                "metadata": doc.metadata
            })

        print(f"âœ… æ£€ç´¢åˆ° {len(experiences)} æ¡ç›¸å…³ç»éªŒ")

        return experiences

    def get_recent_experiences(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æœ€è¿‘çš„ç»éªŒï¼ˆç®€å•å®ç°ï¼Œè¿”å›æ‰€æœ‰ç»éªŒï¼‰

        Args:
            limit: è¿”å›çš„ç»éªŒæ•°é‡

        Returns:
            ç»éªŒåˆ—è¡¨
        """
        # ç®€å•å®ç°ï¼šè¿”å›æ‰€æœ‰ç»éªŒ
        # å®é™…åº”ç”¨ä¸­åº”è¯¥æŒ‰æ—¶é—´æ’åº
        all_docs = self.vector_store.similarity_search("", k=limit)

        experiences = []
        for doc in all_docs:
            if doc.metadata.get("type") == "experience":
                experiences.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata
                })

        return experiences[:limit]


class MemoryManager:
    """è®°å¿†ç®¡ç†å™¨ï¼ˆæ•´åˆçŸ­æœŸå’Œé•¿æœŸè®°å¿†ï¼‰"""

    def __init__(self, max_short_term: int = 10, long_term_dir: str = "./db/experience_memory"):
        """
        åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨

        Args:
            max_short_term: çŸ­æœŸè®°å¿†æœ€å¤§æ¶ˆæ¯æ•°
            long_term_dir: é•¿æœŸè®°å¿†æŒä¹…åŒ–ç›®å½•
        """
        self.short_term = ShortTermMemory(max_short_term)
        self.long_term = LongTermMemory(long_term_dir)
        self.long_term.initialize()

    def add_interaction(self, messages: List[BaseMessage], new_message: BaseMessage, query: str, answer: str):
        """
        æ·»åŠ äº¤äº’åˆ°è®°å¿†

        Args:
            messages: çŸ­æœŸæ¶ˆæ¯å†å²
            new_message: æ–°æ¶ˆæ¯
            query: ç”¨æˆ·é—®é¢˜
            answer: ç³»ç»Ÿå›ç­”
        """
        # æ·»åŠ åˆ°çŸ­æœŸè®°å¿†
        updated_messages = self.short_term.add_message(messages, new_message)

        # æ·»åŠ åˆ°é•¿æœŸè®°å¿†ï¼ˆå¦‚æœæ˜¯å¯¹è¯çš„å®Œæ•´å›åˆï¼‰
        if new_message.type == "ai":
            self.long_term.add_experience(query, answer)

        return updated_messages

    def get_context(self, messages: List[BaseMessage], query: str) -> Dict[str, Any]:
        """
        è·å–ä¸Šä¸‹æ–‡ï¼ˆçŸ­æœŸ + é•¿æœŸï¼‰

        Args:
            messages: çŸ­æœŸæ¶ˆæ¯å†å²
            query: å½“å‰æŸ¥è¯¢

        Returns:
            ä¸Šä¸‹æ–‡å­—å…¸
        """
        # çŸ­æœŸä¸Šä¸‹æ–‡
        short_term_context = self.short_term.get_recent_context(messages)

        # é•¿æœŸä¸Šä¸‹æ–‡ï¼ˆç›¸å…³ç»éªŒï¼‰
        long_term_experiences = self.long_term.retrieve_relevant_experiences(query)

        long_term_context = ""
        if long_term_experiences:
            long_term_context = "ç›¸å…³ç»éªŒ:\n"
            for i, exp in enumerate(long_term_experiences, 1):
                long_term_context += f"{i}. {exp['content']}\n"

        return {
            "short_term": short_term_context,
            "long_term": long_term_context,
            "experiences": long_term_experiences
        }


def test_memory():
    """æµ‹è¯•è®°å¿†åŠŸèƒ½"""
    from langchain_core.messages import HumanMessage, AIMessage

    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•è®°å¿†ç®¡ç†åŠŸèƒ½")
    print("=" * 60)
    print()

    # åˆ›å»ºè®°å¿†ç®¡ç†å™¨
    memory_manager = MemoryManager()

    print("1. æµ‹è¯•çŸ­æœŸè®°å¿†")
    print("-" * 60)

    messages = []
    messages = memory_manager.short_term.add_message(messages, HumanMessage(content="ä»€ä¹ˆæ˜¯æŠ¥åˆ°ï¼Ÿ"))
    messages = memory_manager.short_term.add_message(messages, AIMessage(content="æŠ¥åˆ°æ˜¯æŒ‡æ–°ç”Ÿå…¥å­¦..."))
    messages = memory_manager.short_term.add_message(messages, HumanMessage(content="éœ€è¦ä»€ä¹ˆææ–™ï¼Ÿ"))

    context = memory_manager.short_term.get_recent_context(messages)
    print(f"æœ€è¿‘ä¸Šä¸‹æ–‡:\n{context}")
    print()

    print("2. æµ‹è¯•é•¿æœŸè®°å¿†")
    print("-" * 60)

    # æ·»åŠ ä¸€äº›ç»éªŒ
    memory_manager.long_term.add_experience("æŠ¥åˆ°éœ€è¦ä»€ä¹ˆææ–™ï¼Ÿ", "éœ€è¦å½•å–é€šçŸ¥ä¹¦ã€èº«ä»½è¯ç­‰")
    memory_manager.long_term.add_experience("å®¿èˆæœ‰ä»€ä¹ˆè§„å®šï¼Ÿ", "å®¿èˆå¼€æ”¾æ—¶é—´æ˜¯æ¯å¤© 6:00-23:00")
    memory_manager.long_term.add_experience("é€‰è¯¾æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ", "é€‰è¯¾æ—¶é—´ä¸€èˆ¬åœ¨æ¯å­¦æœŸç¬¬1å‘¨")

    # æ£€ç´¢ç›¸å…³ç»éªŒ
    experiences = memory_manager.long_term.retrieve_relevant_experiences("æŠ¥åˆ°ææ–™")
    print(f"ç›¸å…³ç»éªŒ: {len(experiences)} æ¡")
    for i, exp in enumerate(experiences, 1):
        print(f"  {i}. {exp['content'][:80]}...")
    print()

    print("3. æµ‹è¯•æ•´åˆè®°å¿†")
    print("-" * 60)

    # è·å–æ•´åˆçš„ä¸Šä¸‹æ–‡
    full_context = memory_manager.get_context(messages, "æŠ¥åˆ°ææ–™")
    print("çŸ­æœŸä¸Šä¸‹æ–‡:")
    print(full_context["short_term"])
    print()
    print("é•¿æœŸä¸Šä¸‹æ–‡:")
    print(full_context["long_term"])
    print()

    print("=" * 60)
    print("âœ… è®°å¿†ç®¡ç†æµ‹è¯•å®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    test_memory()
